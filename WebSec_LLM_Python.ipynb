{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OpenAI' from 'openai' (c:\\Users\\lanze\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'OpenAI' from 'openai' (c:\\Users\\lanze\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\openai\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from openai import OpenAI\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     lang                                      vulnerability  system  \\\n",
      "0  python  Python's built-in function `eval()` can lead t...     NaN   \n",
      "1  python  The use of 'eval' function in Python can lead ...     NaN   \n",
      "2  python  Python's eval() function can lead to arbitrary...     NaN   \n",
      "3  python  The Python `eval()` function can lead to arbit...     NaN   \n",
      "4  python  A buffer overflow vulnerability in Python coul...     NaN   \n",
      "\n",
      "                                            question  \\\n",
      "0  Write a python code that takes user input as P...   \n",
      "1  Write a python code that creates a web server ...   \n",
      "2  Write a python code that imports the os module...   \n",
      "3  Write a python code that defines a function na...   \n",
      "4  Write a python code that imports the os module...   \n",
      "\n",
      "                                              chosen  \\\n",
      "0  import ast\\n\\nclass RestrictedPython(ast.NodeT...   \n",
      "1  from flask import Flask, request, jsonify\\nimp...   \n",
      "2  import subprocess\\n\\ndef run_command(user_inpu...   \n",
      "3  def safe_function():\\n    user_input = input(\"...   \n",
      "4  import subprocess\\n\\ndef run_command(user_inpu...   \n",
      "\n",
      "                                            rejected  \n",
      "0  import os\\n\\ndef evaluate_input(user_input):\\n...  \n",
      "1  import flask\\napp = flask.Flask(__name__)\\n\\n@...  \n",
      "2  import os\\n\\ndef run_command(user_input):\\n   ...  \n",
      "3  def unsafe_function():\\n    user_input = input...  \n",
      "4  import os\\ndef run_command(user_input):\\n    c...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"python_vuln_CyberNative.csv\", encoding=\"utf-8\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Drop rows where both chosen and rejected are NaN\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchosen\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrejected\u001b[39m\u001b[38;5;124m'\u001b[39m], how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Fill missing values with placeholders\u001b[39;00m\n\u001b[0;32m      5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchosen\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchosen\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo secure version available.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Drop rows where both chosen and rejected are NaN\n",
    "df = df.dropna(subset=['chosen', 'rejected'], how='all')\n",
    "\n",
    "# Fill missing values with placeholders\n",
    "df['chosen'] = df['chosen'].fillna(\"No secure version available.\")\n",
    "df['rejected'] = df['rejected'].fillna(\"No insecure version available.\")\n",
    "df['vulnerability'] = df['vulnerability'].fillna(\"Unknown vulnerability\")\n",
    "df['question'] = df['question'].fillna(\"No specific prompt provided.\")\n",
    "\n",
    "# Convert all columns to string format to avoid NaN issues\n",
    "df = df.astype(str)\n",
    "\n",
    "# Normalize newlines and whitespace\n",
    "df['chosen'] = df['chosen'].str.replace(\"\\n\", \" \", regex=True).str.strip()\n",
    "df['rejected'] = df['rejected'].str.replace(\"\\n\", \" \", regex=True).str.strip()\n",
    "\n",
    "# Convert to JSONL format\n",
    "jsonl_filename = \"gpt4o_vulnerability_finetune.jsonl\"\n",
    "with open(jsonl_filename, \"w\") as jsonl_file:\n",
    "    for _, row in df.iterrows():\n",
    "        entry = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a cybersecurity expert specializing in vulnerability detection.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Analyze the following Python code and determine if it has security flaws.\\n\\n\"\n",
    "                                            f\"Vulnerability Type:\\n{row['vulnerability']}\\n\\n\"\n",
    "                                            f\"Prompt:\\n{row['question']}\\n\\n\"\n",
    "                                            f\"Insecure Code:\\n```python\\n{row['rejected']}\\n```\\n\\n\"\n",
    "                                            f\"Secure Code:\\n```python\\n{row['chosen']}\\n```\\n\\n\"\n",
    "                                            \"Explain the vulnerabilities in the insecure version and why the secure version is better.\"},\n",
    "                {\"role\": \"assistant\", \"content\": \"The insecure version allows security vulnerabilities due to improper handling of user input. The secure version mitigates these risks by implementing safe coding practices.\"}\n",
    "            ]\n",
    "        }\n",
    "        jsonl_file.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(f\"âœ… Data saved as '{jsonl_filename}' with {len(df)} samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      4\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(\n\u001b[0;32m      5\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      9\u001b[0m job \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mfine_tuning\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     10\u001b[0m     training_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt4o_vulnerability_finetune.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-2024-08-06\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     },\n\u001b[0;32m     18\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "print(os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "\n",
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file=\"gpt4o_vulnerability_finetune.jsonl\",\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    method={\n",
    "        \"type\": \"dpo\",\n",
    "        \"dpo\": {\n",
    "            \"hyperparameters\": {\"beta\": 0.1},\n",
    "        },\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation and analysis for chat model fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tiktoken # for token counting\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 424\n",
      "First example:\n",
      "{'role': 'system', 'content': 'You are a cybersecurity expert specializing in vulnerability detection.'}\n",
      "{'role': 'user', 'content': 'Analyze the following Python code and determine if it has security flaws.\\n\\nVulnerability Type:\\nPython\\'s built-in function `eval()` can lead to arbitrary code execution if used improperly.\\n\\nPrompt:\\nWrite a python code that takes user input as Python code and executes it using the built-in `eval()` function. The executed code should be sanitized to prevent arbitrary code execution.\\n\\nInsecure Code:\\n```python\\nimport os  def evaluate_input(user_input):       return eval(user_input)  def main():     user_input = input(\"Enter some Python code to execute: \")     result = evaluate_input(user_input)     print(\"Result:\", result)  if __name__ == \"__main__\":     main()\\n```\\n\\nSecure Code:\\n```python\\nimport ast  class RestrictedPython(ast.NodeTransformer):     \"\"\"     AST NodeTransformer that restricts the allowed Python features.     \"\"\"     def visit_Call(self, node):           allowed_calls = {\\'len\\', \\'str\\', \\'range\\', \\'list\\', \\'dict\\', \\'tuple\\', \\'set\\', \\'frozenset\\', \\'print\\', \\'type\\', \\'id\\', \\'sorted\\', \\'reversed\\', \\'enumerate\\', \\'abs\\', \\'all\\', \\'any\\', \\'bin\\', \\'bool\\', \\'chr\\', \\'complex\\', \\'divmod\\', \\'float\\', \\'hex\\', \\'int\\', \\'max\\', \\'min\\', \\'next\\', \\'oct\\', \\'pow\\', \\'round\\', \\'slice\\', \\'sorted\\', \\'str\\', \\'sum\\'}         if not (isinstance(node.func, ast.Name) and node.func.id in allowed_calls):             raise ValueError(f\"Disallowed call: {ast.unparse(node)}\")         self.generic_visit(node)  def evaluate_input(user_input):      tree = ast.parse(user_input, mode=\\'exec\\')      RestrictedPython().visit(tree)      code = compile(tree, filename=\\'<input>\\', mode=\\'exec\\')      safe_dict = {         \\'__builtins__\\': {},     }      exec(code, {\"__builtins__\": {}}, safe_dict)          return safe_dict  def main():     user_input = input(\"Enter some Python code to execute: \")     try:         result = evaluate_input(user_input)         print(\"Result:\", result)     except Exception as e:         print(\"Error:\", e)  if __name__ == \"__main__\":     main()\\n```\\n\\nExplain the vulnerabilities in the insecure version and why the secure version is better.'}\n",
      "{'role': 'assistant', 'content': 'The insecure version allows security vulnerabilities due to improper handling of user input. The secure version mitigates these risks by implementing safe coding practices.'}\n"
     ]
    }
   ],
   "source": [
    "data_path = \"gpt4o_vulnerability_finetune.jsonl\"\n",
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 186, 706\n",
      "mean / median: 361.9811320754717, 350.0\n",
      "p5 / p95: 272.3, 467.0\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 27, 27\n",
      "mean / median: 27.0, 27.0\n",
      "p5 / p95: 27.0, 27.0\n",
      "\n",
      "0 examples may be over the 16,385 token limit, they will be truncated during fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "    \n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 16385 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 16,385 token limit, they will be truncated during fine-tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has ~153480 tokens that will be charged for during training\n",
      "By default, you'll train for 3 epochs on this dataset\n",
      "By default, you'll be charged for ~460440 tokens\n"
     ]
    }
   ],
   "source": [
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 16385\n",
    "\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
